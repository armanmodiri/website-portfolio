[
    {
        "id": 1,
        "title": "The Cloud Resume Challenge",
        "date": "Dec 08, 2025",
        "imageCaption": "Starting the journey with Azure Storage Static Websites.",
"content": "I work with Azure everyday. While I typically work within the compute, networking and Identity sections, a part of me which wanted to explore the DevOps side. When I stumbled across the <a href='https://cloudresumechallenge.dev/' target='_blank' style='color: var(--magma-orange);'>Cloud Resume Challenge</a>, I knew I would take it on eventually. This is my journey.<br><br>To start, I needed to convert my resume which was made in Word to HTML. I used Gemini 3 Pro to complete the mountain of manual effort needed to convert the Word doc into an HTML file. After a few hours of fiddling around, I was able to sprinkle in a bit of CSS to get the aesthetic I was looking for. After viewing countless portfolio’s, everyone had included a bit of their personality into their brand. As an avid rock climber, I knew I had to add my personal touch.<br><br>I used VSCode with the preview plugin to quickly make changes to the <code>index.html</code>, <code>script.js</code> and <code>style.css</code> file. For the journal section that you’re reading this on, I went with a simple <code>posts.json</code> file that can be modified to add additional entries as new projects come down the line. After creating a <code>404.html</code> file with some witty OSPF humor and a jpg file with my favorite local crag, I was ready to tackle the first Azure portion.<br><br><strong>Article used:</strong> <a href='https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-static-website' target='_blank' style='color: var(--magma-orange);'>Azure Storage Static Website</a><br><br>With an Azure tenant created, a resource group followed which led to my storage account getting setup. Standard SSD with LRS storage is all we need since this is a non-critical website. From there I can turn on the static website functionality, name my index and error path and finally allow my public IP to access the resources inside of the <code>$web</code> storage container to add the files we created earlier.<br><br><img src='Blog%20Photos/1%20-webContainerV1.png' alt='Web Container Setup' /><br><br>For this project, I needed to buy the armanmodiri.com domain and went with Cloudflare as my DNS and SSL provider. To verify that the domain was truly mine, I needed to add <code>asverify.amodcrc.z20.web.core.windows.net</code> as a CNAME record for my storage account to get the custom domain verification. A 15 minute wait and a few refreshes using whatsmydns.com and I was able to verify my domain.<br><br><img src='Blog%20Photos/2%20-dnsPropagationCheck.png' alt='DNS Propagation Check' /><br><br><img src='Blog%20Photos/3%20-CustomDomainRegistration.png' alt='Custom Domain Registration' /><br><br>I could access the website directly using the azurewebsites.net URL but I was having issues having the traffic route correctly when reaching armanmodiri.com directly. I was getting the 404 error below:<br><br><pre><code>HttpStatusCode: 404\nErrorCode: WebContentNotFound\nRequestId : 9c080c35-a01e-00dd-14e9-679035000000\nTimeStamp : 2025-12-08T02:22:39.9023296Z</code></pre><br>The image below shows the flow of traffic causing our error:<br><br><img src='Blog%20Photos/4%20-AzureSSLrejection.jpg' alt='Azure SSL Rejection Flow' /><br><div style='text-align: center; font-size: 0.8em; color: #888;'>Created with Gemini Pro 3</div><br><br>I stumbled across <a href='https://melcher.dev/2019/06/azure-storage-static-website-ssl-and-root-domain-dns/' target='_blank' style='color: var(--magma-orange);'>this article</a> while trying to troubleshoot. The fix is to route Cloudflare to Azure’s Content Delivery Network (CDN). The author of this article added the critical piece of information saying that you cannot natively serve your website on a root domain using Azure Storage Static Websites:<br><br><ul><li>armanmodiri.com (Not supported)</li><li>www.armanmodiri.com (Supported)</li></ul><br>Once you create a CDN in Azure, you can create an endpoint that exposes the blob URL where the website is statically hosted with the URL turning into <code>armanmodiri.azureedge.net</code>.<br><br>This all sounds great but there was one issue. The article was released in 2019 and Azure CDN is set to be retired on September 2027. Microsoft’s does have a plug and play replacement, Azure Front Door. This is where I decided to deviate away from the standard Cloud Resume Challenge as times change and I did not want to pay $35/mo for the Standard Azure Front Door SKU to maintain native HTTPS connectivity to my website.<br><br>Knowing that this would come up, Microsoft has created an entirely different service: <strong>Azure Static Web Apps (SWA)</strong>. Key benefits that drew me to SWA:<br><ul><li>HTTPS all the way from Cloudflare to SWA (native support)</li><li>CI/CD automatically (GitHub Actions)</li></ul><br>Now that I am pivoting, I needed to push the local repository I made to Github. A few minutes of fiddling around due to Google Drive and Git fighting, I was able to get source control setup in VSCode, the repo pushed to GitHub and my Static Web App created.<br><br>With this new SWA, I need to add my custom domain again.<br><br><img src='Blog%20Photos/5%20-swaDNStxt.png' alt='SWA DNS TXT Record' /><br><br>While I was waiting for the new TXT record to propagate, I deleted the storage account. The work day was approaching, this was a perfect time to step away.<br><br>After checking 8 hours later, we are good to go! The armanmodiri.com custom domain was now validated. All I needed to do was set it as a default and voila.<br><br><img src='Blog%20Photos/6%20-swaDefaultPage.png' alt='SWA Default Page' /><br><br>My next challenge was making sure that users were always using HTTPS and directed to the non “www.” version of the site. I achieved this by registering the subdomain in the same section under SWA, adding the verification TXT record in Cloudflare, forcing HTTPS and creating a 301 permanent redirect to ensure visitors always land on armanmodiri.com.<br><br>The GitHub Action which was trying to publish the main branch to the SWA was failing due to Onyx looking for a <code>package.json</code> file to run. Given that I am using a simple index.html as the core, I needed a way to skip this check. By inserting <code>app_build_command: 'true'</code> into the YAML file, we are able to confirm that the build was successful and the action can continue.<br><br>After pushing the change, the SWA CI/CD Action started building and deploying the job. A minute later and I had my first green checkmark with one error. There was a failure to remove an extra header from the git config. The issue is the extra header is having a token saved to a locked file, when it tries to get deleted, there is an error thrown.<br><br>The fix is simple, adding the following line <code>persist-credentials: false</code> to the YAML file alleviates the issue.<br><br><img src='Blog%20Photos/7%20-githubActionsWorkflow.png' alt='GitHub Actions Workflow' /><br><br>Bang! The website is up and running. When I commit and push to git, it automatically updates the website! This is the first time I am using any sort of CI/CD tool and I am impressed with its functionality and seamless integration.<br><br>Time to fix that 1204 placeholder value for the API Request counter (site visits). The first step is creating an Azure CosmosDB account using the table API. Of course, we are going to utilize the free tier given our lightweight usage.<br><br>All of the code in this project is pushed to Github, we can’t have any sensitive information available for anyone on the internet to take advantage of.<br><br><em>I made a mistake putting my town on the initial commit and spend a hour figuring out an easy way to remove it, there was no easy way other than creating an orphan branch and making that my new main - double check what gets published to the internet</em><br><br>A <code>.gitignore</code> file is what I need to make sure the file with my secrets doesn’t get shared to the internet. To house the connection string locally, I created a <code>local.settings.json</code> file with the primary connection string for my CosmosDB. The next step was to vibe code the <code>function_app.py</code> file which is used to reach the database, update the value and statically change the value on the website. I needed to add the following models in a virtual environment for my python file to be happy:<br><ul><li>azure-functions</li><li>azure-data-tables</li></ul><br>Since the connection string will not be pushed to Github, I need to house it within the Managed Functions for environment variables to be filled by Azure when the website is accessed. An “api” folder was created that housed the <code>function_app.py</code>, <code>hosts.json</code> and <code>requirements.txt</code> files. Finally I updated the .github workflow to find “api location folder”.<br><br>I changed the logic for the placeholder API request value and added the CosmosDB string directly in the environment variables within SWA.<br><br><img src='Blog%20Photos/8%20-cosmosDBstring.png' alt='Cosmos DB String' /><br><br>We need a place to store our API Requests which is really a visitor counter. I made sure to use the manual throughput functionality available with free tier to stay under my 1000 RU/s limit.<br><br>As expected, the first iteration was not successful. The errors below are related to Cloudflare’s visitor counter and not a priority since it doesn’t affect the websites functionality. DNS is working as expected. Time to troubleshoot.<br><br><img src='Blog%20Photos/9%20-apiFailure.png' alt='API Failure Log' /><br><br>The next logical step would be to locally test the database connection first to make sure our API call is working as expected. To debug the failure, I tested used CURL to ping the API endpoint, proving the server was online. All that was left was to run local Python script that connected directly to the database using the same increment functionality.<br><br><code>curl -v https://armanmodiri.com/api/GetVisitorCount</code><br><br>The backend logic was working as expected, this pointed me to the front end. A quick pass through to the tool that made this all possible, Gemini 3 Pro. A few minutes after pushing to GitHub, the first iteration of this website was complete!<br><br><hr><br>This website was built over the course of a week (~18 hours) after reading <em>Deep Work</em> published by Cal Newport. The goal was to utilize parts of Azure that were outside of the traditional stack I am familiar with. Developing the website at this speed would have not been possible without my use of AI."    },
    {
        "id": 2,
        "title": "What's Next to learn?",
        "date": "Present",
        "content": "With the Cloud Resume Challenge complete, I'm ready to connect my CCNA background with modern DevOps. My goal is to dive into the Cisco DevNet path and learn how to apply CI/CD pipelines to network infrastructure. I want to move beyond manual CLI & GUI configs and start treating the network as code, automating deployments with Python and Ansible similar to how I used GitHub Actions for this website."    
    }
]